{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from bitsandbytes.triton.int8_matmul_mixed_dequantize import (\n",
    "    int8_matmul_mixed_dequantize,\n",
    ")\n",
    "\n",
    "from bitsandbytes.triton.quantize_rowwise import quantize_rowwise\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='output.log', level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def get_time(k, fn, X, W, repeat):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(repeat):\n",
    "        fn(X, W)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    ms = (end - start) / repeat * 1000\n",
    "    logger.info(f\"time {k}: {ms:.3f} ms\")\n",
    "\n",
    "def get_time_swichback(k, fn, X, W, b, repeat):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(repeat):\n",
    "        fn(X, W, b)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    ms = (end - start) / repeat * 1000\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(repeat):\n",
    "        fn(X, W, b)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    ms = (end - start) / repeat * 1000\n",
    "    logger.info(f\"time {k} after fit-params: {ms:.3f} ms\")\n",
    "    return ms\n",
    "\n",
    "def standatrt(x, w, b):\n",
    "    return F.linear(x, w, b)\n",
    "\n",
    "def swichback(X_3D, W, b):\n",
    "    X = X_3D.view(-1, X_3D.size(-1))\n",
    "    X_int8, state_X = quantize_rowwise(X)\n",
    "    W_int8, state_W = quantize_rowwise(W)\n",
    "    return int8_matmul_mixed_dequantize(X_int8, W_int8.t(), state_X, state_W, None).view(*X_3D.size()[:-1], -1)\n",
    "\n",
    "def mul_matrix(x_in, x_out, w_in, w_out, repeat, profiler_results_path='profiler_results'):\n",
    "    x = torch.randn(x_in, x_out, dtype=torch.float16).cuda()\n",
    "    w = torch.randn(w_in, w_out, dtype=torch.float16).cuda()\n",
    "    b = torch.empty(w_in, dtype=torch.float16).cuda()\n",
    "    \n",
    "    logger.info(f\"Running fwd with x size: {x.size()}, w size: {w.size()}\")\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA, ProfilerActivity.XPU], \n",
    "        record_shapes=True,\n",
    "        with_flops=True,\n",
    "        profile_memory=True\n",
    "    ) as prof:\n",
    "        with record_function(\"standard_fwd\"):\n",
    "            standart_time = get_time_swichback(\"standard_fwd\", standatrt, x, w, b, repeat)\n",
    "        with record_function(\"swichback\"):\n",
    "            swichback_time = get_time_swichback(\"swichback\", swichback, x, w, b, repeat)\n",
    "\n",
    "    prof.export_chrome_trace(f\"profiler_results/{profiler_results_path}_({x.shape[0]},{x.shape[1]})_({w.shape[0]},{w.shape[1]}).json\")\n",
    "    \n",
    "    logger.info(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "    logger.info('\\n')\n",
    "    return standart_time, swichback_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_times(layers, sequence_length, batch_sizes, repeat=64):\n",
    "    standard_times = []\n",
    "    switchback_times = []\n",
    "    optimal_times = []\n",
    "\n",
    "    total_standard_times = []\n",
    "    total_switchback_times = []\n",
    "    total_optimal_times = []\n",
    "\n",
    "    for batch in batch_sizes:\n",
    "        batch_standard_times = {}\n",
    "        batch_switchback_times = {}\n",
    "        batch_optimal_times = {}\n",
    "\n",
    "        total_standard_time = 0\n",
    "        total_switchback_time = 0\n",
    "        total_optimal_time = 0\n",
    "\n",
    "        for key, value in layers.items():\n",
    "            layer_name = key\n",
    "            size_1, size_2 = value\n",
    "            batch_size_adjusted = batch * sequence_length\n",
    "\n",
    "            standard_time, switchback_time = mul_matrix(\n",
    "                batch_size_adjusted, size_1, size_2, size_1, repeat=repeat\n",
    "            )\n",
    "\n",
    "            batch_standard_times[layer_name] = standard_time\n",
    "            batch_switchback_times[layer_name] = switchback_time\n",
    "            \n",
    "            optimal_time = min(standard_time, switchback_time)\n",
    "            batch_optimal_times[layer_name] = optimal_time\n",
    "\n",
    "            total_standard_time += standard_time\n",
    "            total_switchback_time += switchback_time\n",
    "            total_optimal_time += optimal_time\n",
    "\n",
    "        standard_times.append(batch_standard_times)\n",
    "        switchback_times.append(batch_switchback_times)\n",
    "        optimal_times.append(batch_optimal_times)\n",
    "\n",
    "        total_standard_times.append(total_standard_time)\n",
    "        total_switchback_times.append(total_switchback_time)\n",
    "        total_optimal_times.append(total_optimal_time)\n",
    "\n",
    "    return {\n",
    "        \"batch_sizes\": batch_sizes,\n",
    "        \"standard_times\": standard_times,\n",
    "        \"switchback_times\": switchback_times,\n",
    "        \"optimal_times\": optimal_times,\n",
    "        \"total_standard_times\": total_standard_times,\n",
    "        \"total_switchback_times\": total_switchback_times,\n",
    "        \"total_optimal_times\": total_optimal_times\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "LlamaDecoderLayer(\n",
    "  (self_attn): LlamaSdpaAttention(\n",
    "    (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
    "    (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
    "    (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
    "    (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
    "    (rotary_emb): LlamaRotaryEmbedding()\n",
    "  )\n",
    "  (mlp): LlamaMLP(\n",
    "    (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
    "    (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
    "    (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
    "    (act_fn): SiLU()\n",
    "  )\n",
    "  (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
    "  (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\n",
    "    'q_proj': [2048, 2048],\n",
    "    'k_proj': [2048, 256],\n",
    "    'v_proj': [2048, 256],\n",
    "    'o_proj': [2048, 2048],\n",
    "    'gate_proj': [2048, 5632],\n",
    "    'up_proj': [2048, 5632],\n",
    "    'down_proj': [5632, 2048]\n",
    "}\n",
    "\n",
    "sequence_length = 128\n",
    "batch_sizes = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "results = calculate_times(layers,sequence_length,batch_sizes)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def prepare_layer_data(times):\n",
    "    layer_data = {layer: [] for layer in times[0].keys()}\n",
    "    for layer_times in times:\n",
    "        for layer, time in layer_times.items():\n",
    "            layer_data[layer].append(time)\n",
    "    return layer_data\n",
    "\n",
    "standard_layer_data = prepare_layer_data(results['standard_times'])\n",
    "switchback_layer_data = prepare_layer_data(results['switchback_times'])\n",
    "optimal_layer_data = prepare_layer_data(results['optimal_times'])\n",
    "\n",
    "x_legend_dict = {}\n",
    "for x in range(len(batch_sizes)):\n",
    "    x_legend_dict[x] = batch_sizes[x]\n",
    "\n",
    "def plot_layer_data(batch_sizes, standard_layer_data, switchback_layer_data, optimal_layer_data):\n",
    "    for key in standard_layer_data.keys():\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(batch_sizes, optimal_layer_data[key], label=f'optimal_{key}', marker='*', color = 'green', linewidth=10)\n",
    "        plt.plot(batch_sizes, standard_layer_data[key], label=f'standard_{key}', marker='o', color ='blue')\n",
    "        plt.plot(batch_sizes, switchback_layer_data[key], label=f'switchback_{key}', marker='x', color = 'red')\n",
    "        \n",
    "        plt.title(f'Performance of {key}: ({layers[key][0]};{layers[key][0]}) layer')\n",
    "        plt.xlabel('Batch Size')\n",
    "        plt.ylabel('Time ')\n",
    "        plt.xscale('log')\n",
    "        plt.xticks(ticks=batch_sizes, labels=[x_legend_dict[i] for i in range(len(batch_sizes))])\n",
    "        plt.legend(title='Components')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_layer_data(batch_sizes, standard_layer_data, switchback_layer_data, optimal_layer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "x_legend_dict = {}\n",
    "for x in range(len(batch_sizes)):\n",
    "    x_legend_dict[x] = batch_sizes[x]\n",
    "\n",
    "standard_layer_data = prepare_layer_data(results['standard_times'])\n",
    "switchback_layer_data = prepare_layer_data(results['switchback_times'])\n",
    "optimal_layer_data = prepare_layer_data(results['optimal_times'])\n",
    "def plot_layer_data(batch_sizes, standard_layer_data, switchback_layer_data, optimal_layer_data):\n",
    "    num_layers = len(standard_layer_data)  # Get the number of layers\n",
    "    ncols = 4  # Set number of columns for subplots\n",
    "    nrows = (num_layers + 1) // ncols  # Calculate rows needed to fit all layers\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 6 * nrows), constrained_layout=True)\n",
    "\n",
    "    # Ensure axes is iterable, flatten if more than one row\n",
    "    if nrows > 1:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for ax, key in zip(axes, standard_layer_data.keys()):\n",
    "        ax.plot(batch_sizes, optimal_layer_data[key], label=f'optimal_{key}', marker='*', color='green', linewidth=5)\n",
    "        ax.plot(batch_sizes, standard_layer_data[key], label=f'standard_{key}', marker='o', color='blue')\n",
    "        ax.plot(batch_sizes, switchback_layer_data[key], label=f'switchback_{key}', marker='x', color='red')\n",
    "\n",
    "        ax.set_title(f'Performance of {key}: ({layers[key][0]};{layers[key][1]}) layer')\n",
    "        ax.set_xlabel('Batch Size')\n",
    "        ax.set_ylabel('Time ')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xticks(batch_sizes)\n",
    "        ax.set_xticklabels([str(x_legend_dict[i]) for i in range(len(batch_sizes))])\n",
    "        ax.legend(title='Components')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Hide any unused subplots if they exist\n",
    "    for i in range(num_layers, nrows * ncols):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_layer_data(batch_sizes, standard_layer_data, switchback_layer_data, optimal_layer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = range(len(batch_sizes))  \n",
    "\n",
    "x_labels = {}\n",
    "for x in range(len(batch_sizes)):\n",
    "    x_labels[x] = batch_sizes[x]\n",
    "\n",
    "standard_total_times = results['total_standard_times']\n",
    "switchback_total_times = results['total_switchback_times']\n",
    "optimal_total_times = results['total_optimal_times']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.plot(batch_sizes, optimal_total_times, label=f'Avarage_optimal', marker='*', color = 'green', linewidth=10)\n",
    "plt.plot(batch_sizes, standard_total_times, label=f'Avarage_standard', marker='o', color ='blue')\n",
    "plt.plot(batch_sizes, switchback_total_times, label=f'Avarage_switchback', marker='x', color = 'red')\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time ')\n",
    "plt.xscale('log')\n",
    "plt.xticks(ticks=batch_sizes, labels=[x_legend_dict[i] for i in range(len(batch_sizes))])\n",
    "plt.legend(title='Components')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_speedup(standard_times, switchback_times, total_standard_times, total_switchback_times):\n",
    "    layer_speedup_data = {layer: [] for layer in standard_times[0].keys()}\n",
    "    overall_speedup = []\n",
    "\n",
    "    for standard_layer_times, switchback_layer_times in zip(standard_times, switchback_times):\n",
    "        for layer in layer_speedup_data.keys():\n",
    "            standard_time = standard_layer_times[layer]\n",
    "            switchback_time = switchback_layer_times[layer]\n",
    "            speedup = -100 * (switchback_time - standard_time) / standard_time\n",
    "            layer_speedup_data[layer].append(speedup)\n",
    "\n",
    "\n",
    "    for total_standard_time, total_switchback_time in zip(total_standard_times, total_switchback_times):\n",
    "        overall_speedup_value = -100 * (total_switchback_time - total_standard_time) / total_standard_time\n",
    "        overall_speedup.append(overall_speedup_value)\n",
    "\n",
    "    return layer_speedup_data, overall_speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_speedup_data, overall_speedup = calculate_speedup(\n",
    "    results['standard_times'], \n",
    "    results['switchback_times'],\n",
    "    results['total_standard_times'],\n",
    "    results['total_switchback_times']\n",
    ")\n",
    "layer_speedup_df = pd.DataFrame(layer_speedup_data, index=batch_sizes)\n",
    "layer_speedup_df.index.name = 'Batch Size'\n",
    "\n",
    "overall_speedup_df = pd.DataFrame({'Overall Speedup (%)': overall_speedup}, index=batch_sizes)\n",
    "overall_speedup_df.index.name = 'Batch Size'\n",
    "\n",
    "layer_speedup_df['Overall Speedup (%)'] = overall_speedup_df['Overall Speedup (%)']\n",
    "print(\"Layer Speedup Data (Swichback vs Standard) with Overall Speedup:\")\n",
    "layer_speedup_df.round(2)\n",
    "layer_speedup_df.round(2).to_csv('Layer Speedup Data (Swichback vs Standard) with Overall Speedup.csv')\n",
    "layer_speedup_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_optimal_speedup_data, overall_optimal_speedup = calculate_speedup(\n",
    "    results['standard_times'], \n",
    "    results['optimal_times'],\n",
    "    results['total_standard_times'],\n",
    "    results['total_optimal_times']\n",
    ")\n",
    "\n",
    "layer_optimal_speedup_df = pd.DataFrame(layer_optimal_speedup_data, index=batch_sizes)\n",
    "layer_optimal_speedup_df.index.name = 'Batch Size'\n",
    "\n",
    "overall_optimal_speedup_df = pd.DataFrame({'Overall Speedup (%)': overall_optimal_speedup}, index=batch_sizes)\n",
    "overall_optimal_speedup_df.index.name = 'Batch Size'\n",
    "\n",
    "layer_optimal_speedup_df['Overall Speedup (%)'] = overall_optimal_speedup_df['Overall Speedup (%)']\n",
    "\n",
    "print(\"Layer Speedup Data (Optimal vs Standard) with Overall Speedup:\")\n",
    "layer_optimal_speedup_df.round(2).to_csv('Layer Speedup Data (Optimal vs Standard) with Overall Speedup.csv')\n",
    "layer_optimal_speedup_df.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
